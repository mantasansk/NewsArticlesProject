{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7062a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6ed386",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e1cb52",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163b4de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data into pandas dataframes\n",
    "data_lrt = pd.read_csv(\"Data/data_lrt.csv\", index_col=0)\n",
    "data_15min = pd.read_csv(\"Data/data_15min.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c57f6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lrt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c09a8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_15min.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf9fc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"lrt.lt:{data_lrt.shape[0]}, 15min.lt:{data_15min.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3543f0aa",
   "metadata": {},
   "source": [
    "- Both tables have source, category, date, title, score and last_updated columns.\n",
    "- There are 133437 entries from lrt.lt data and 72107 entries from 15min.lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd26c9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining both dataframes\n",
    "df = pd.concat([data_lrt, data_15min]).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b9d6c6",
   "metadata": {},
   "source": [
    "### Changing data types and converting categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2137fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ce4d3d",
   "metadata": {},
   "source": [
    "##### No columns have missing values but source, category, date and last_updated columns have incorrect data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66c68e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing columns' data types\n",
    "df[\"source\"] = df[\"source\"].astype(\"category\")\n",
    "df[\"category\"] = df[\"category\"].astype(\"category\")\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df[\"last_updated\"] = pd.to_datetime(df[\"last_updated\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d5932b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aee72a",
   "metadata": {},
   "source": [
    "##### Now all columns have correct data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e7c2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting categories\n",
    "# \"pozicija\" category only exists in lrt.lt website and it's structure is the same as \"nuomones\" category, so it is converted to\n",
    "# \"nuomones category\"\n",
    "df.loc[df[\"category\"]==\"pozicija\", \"category\"] = \"nuomones\"\n",
    "\n",
    "# \"lrt-tyrimai\" category only exists in lrt.lt website and it's structure is similar to \"kriminalai\" category from 15min.lt\n",
    "# website, so it is converted to \"kriminalai\" category\n",
    "df.loc[df[\"category\"]==\"lrt-tyrimai\", \"category\"] = \"kriminalai\"\n",
    "\n",
    "df[\"category\"] = df[\"category\"].cat.remove_categories([\"pozicija\", \"lrt-tyrimai\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc3d68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category\"].unique().to_list(), len(df[\"category\"].unique().to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6daae47",
   "metadata": {},
   "source": [
    "##### There are 15 categories now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432d9753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this project only two columns will be needed: category and title\n",
    "df_cat = df.copy()[[\"category\", \"title\"]]\n",
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbb7ebc",
   "metadata": {},
   "source": [
    "### Removing title duplicates and keeping categories of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4402f7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_rare_duplicates(df):\n",
    "    \"\"\"Remove duplicated titles while keeping the less popular category\"\"\"\n",
    "    # Calculating the number of titles for every category in a dataframe\n",
    "    sorted_cat = list(df[\"category\"].value_counts().sort_values(ascending=True).index)\n",
    "    cat_num = {}\n",
    "    for num, cat in enumerate(sorted_cat):\n",
    "        cat_num[cat] = num\n",
    "    \n",
    "    # Finding duplicated titles\n",
    "    duplicated_titles = df[df.duplicated(\"title\")][\"title\"].values\n",
    "    \n",
    "    # If title was put in different categories, keeping the less popular one\n",
    "    for t in duplicated_titles:\n",
    "        smaller_cat = None\n",
    "        rows = df[df[\"title\"] == t][\"category\"]\n",
    "        indexes = list(rows.index)\n",
    "        categories = list(rows.values)\n",
    "        for c in categories:\n",
    "            if not smaller_cat:\n",
    "                smaller_cat = c\n",
    "            else:\n",
    "                if cat_num[c] < cat_num[smaller_cat]:\n",
    "                    smaller_cat = c\n",
    "        df.loc[indexes, \"category\"] = smaller_cat\n",
    "    \n",
    "    return df[~df.duplicated(\"title\")].reset_index(drop=True)  # Fully removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53952335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_title_duplicates_set_categories(df, cat_to_keep):\n",
    "    \"\"\"Only keep categories of interest and remove duplicated titles\"\"\"\n",
    "    # Keeping categories of interest\n",
    "    df[\"category\"] = df[\"category\"].cat.set_categories(cat_to_keep)\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Droping absolute duplicates\n",
    "    df = df[~df.duplicated([\"category\", \"title\"])].reset_index(drop=True)\n",
    "    \n",
    "    # Changing remaining duplicates' categories to the ones that are less popular in the dataframe\n",
    "    df = keep_rare_duplicates(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72b707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of titles for each category\n",
    "df_cat[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cd5642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing which categories to keep\n",
    "categories_to_keep = [\"verslas\", \"sportas\", \"kultura\", \"mokslas-ir-it\",\n",
    "                      \"nuomones\", \"eismas\", \"kriminalai\", \"sveikata\", \"muzika\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f768ef59",
   "metadata": {},
   "source": [
    "##### Choosing 9 most distinguishable categories, shown above, out of 15 because:\n",
    "- categories 'lietuvoje', 'pasaulyje', 'veidai' and 'gyvenimas' are too abstract\n",
    "- 'tavo-lrt' category only exists on lrt.lt website\n",
    "- 'maistas' category has too few data (120 titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c48d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicates from data\n",
    "data = remove_title_duplicates_set_categories(df_cat, categories_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e19dd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of duplicated titles:{data[data.duplicated('title')].shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1a893a",
   "metadata": {},
   "source": [
    "### Finding top 10 similar titles' distribution between categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc651de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a pandas dataframe\n",
    "ex_data = data.copy()\n",
    "ex_data[categories_to_keep] = 0\n",
    "ex_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38d0a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading sentence transformer fitted for Lithuanian language\n",
    "embedder = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d39101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all titles into the list\n",
    "corpus = list(ex_data[\"title\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e19c670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding titles\n",
    "# !TAKES 40 MINUTES! Set 'proceed_en = True' if you want to encode titles from the start. Else, cell below loads the encoded\n",
    "# titles\n",
    "proceed_en = False\n",
    "if proceed_en:\n",
    "    corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
    "\n",
    "    with open(\"encoder_multi.sv\", \"wb\") as f: \n",
    "        pickle.dump(corpus_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dd1d92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Finding top 10 titles and their categories\n",
    "# !TAKES MORE THAN 6 HOURS! Set 'proceed_top10 = True' if you want to calculate the results from the start. Else, dataframe\n",
    "# with calculated results will be loaded in - 2. Data Analysis - section\n",
    "proceed_top10 = False\n",
    "if proceed_top10:\n",
    "    top_k = 10 + 1\n",
    "    cat_pos = dict(zip(categories_to_keep, [categories_to_keep.index(i) for i in categories_to_keep]))\n",
    "    results_form = [0 for i in range(len(categories_to_keep))]\n",
    "    t = 0\n",
    "\n",
    "    for title in corpus:\n",
    "        query_embedding = embedder.encode(title, convert_to_tensor=True)\n",
    "\n",
    "        # Using cosine-similarity and torch.topk to find the highest 10 scores\n",
    "        cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "        top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "        results = results_form.copy()\n",
    "        t += 1\n",
    "        print(t)\n",
    "        for idx in top_results[1][1:]:\n",
    "            results[cat_pos[ex_data[ex_data[\"title\"] == corpus[idx]][\"category\"].values[0]]] += 1\n",
    "\n",
    "        ex_data.loc[ex_data[ex_data[\"title\"] == title].index[0], categories_to_keep] = results\n",
    "    \n",
    "    ex_data.to_csv(\"Data/pur_df.csv\")\n",
    "    pur_df = ex_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d827818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataframe with top 10 titles' distribution between categories included\n",
    "pur_df = pd.read_csv(\"Data/pur_df.csv\", index_col=0)\n",
    "pur_df[\"category\"] = pur_df[\"category\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87514a7",
   "metadata": {},
   "source": [
    "### Adding two more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff374eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding length of title\n",
    "pur_df[\"title_length\"] = pur_df[\"title\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58234796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding number of words in a title\n",
    "pur_df[\"word_count\"] = pur_df[\"title\"].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67de93b",
   "metadata": {},
   "source": [
    "#### In this section:\n",
    "- data was loaded\n",
    "- categories transformed\n",
    "- duplicates removed\n",
    "- additional features created"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ae88ec",
   "metadata": {},
   "source": [
    "# 2. Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af13b807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final dataframe\n",
    "pur_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76a9ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pur_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48dcd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(11, 6))\n",
    "pur_df[\"category\"].value_counts().sort_values(ascending=True).plot(kind=\"barh\")\n",
    "plt.xlabel(\"Total Number of Titles\")\n",
    "plt.ylabel(\"Categories\")\n",
    "plt.title(\"Distribution of Titles Between Categories in the Final Dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c5ba11",
   "metadata": {},
   "source": [
    "##### Final dataset has 99499 titles, 25 thousands or 1/4 of them are placed in 'verslas' category.\n",
    "\n",
    "##### Other popular categories are 'sportas' and 'kultura' having around 15 000 titles each.\n",
    "\n",
    "##### Least common categories are 'muzika' and 'sveikata' having around 5 000 titles each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e625c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pur_df[[\"title_length\", \"word_count\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019b357e",
   "metadata": {},
   "source": [
    "##### Average length of all titles is 75 characters and there are 10 words on average in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c0e6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating mean length of a title between categories\n",
    "s_tl = pur_df.groupby(\"category\")[\"title_length\"].mean().sort_index()\n",
    "s_tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4203de7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating mean number of words in a title between categories\n",
    "s_wc = pur_df.groupby(\"category\")[\"word_count\"].mean().sort_index()\n",
    "s_wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02943930",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette([\"red\", \"orange\", \"yellow\", \"green\", \"cyan\", \"blue\", \"purple\", \"pink\", \"black\"])\n",
    "sns.scatterplot(x=s_wc, y=s_tl, hue=s_wc.index)\n",
    "plt.legend(loc=4)\n",
    "plt.xlabel(\"Average Number of Words in a Title\")\n",
    "plt.ylabel(\"Average Length of a Title\")\n",
    "plt.title(\"Average Title Length and Number of Words Between Categories\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9062b4c3",
   "metadata": {},
   "source": [
    "##### Linear trend can be seen between average length of a title and number of words in it.\n",
    "\n",
    "##### The largest average titles are in categories 'sveikata' and 'muzika' while the shortest are in 'nuomones' category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca22886",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 9))\n",
    "np.random.seed(420)\n",
    "sns.scatterplot(x=pur_df[\"word_count\"]+np.random.uniform(low=-0.4, high=0.4, size=pur_df.shape[0]),\n",
    "                y=pur_df[\"title_length\"], hue=pur_df[\"category\"], alpha=0.2, size=0.1)\n",
    "plt.xlabel(\"Number of Words in a Title\")\n",
    "plt.ylabel(\"Length of a Title\")\n",
    "plt.title(\"Distribution of Titles by Number of Words and It's Length\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7fb86a",
   "metadata": {},
   "source": [
    "##### Linear trend can be seen again.\n",
    "##### Majority of titles have between 4 and 19 words and their length is between 25 and 140 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e3a962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating top 10 similar titles' distribution between categories for each category\n",
    "stat_tab = pur_df[pur_df.columns[:-2]].groupby(\"category\").sum().reset_index()\n",
    "\n",
    "# Calculating total number of scores for each category\n",
    "stat_tab[\"total\"] = stat_tab[categories_to_keep].sum(axis=1)\n",
    "stat_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51d3836",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Converting scores to percentages within each category\n",
    "stat_tab[categories_to_keep] = stat_tab.apply(lambda x: x[categories_to_keep]/x[\"total\"]*100, axis=1).apply(lambda x: x.round(1))\n",
    "stat_tab = stat_tab.set_index(\"category\").drop(\"total\", axis=1)\n",
    "stat_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7084ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 9))\n",
    "\n",
    "c_map = sns.color_palette([\"red\", \"orange\", \"yellow\", \"green\", \"cyan\", \"blue\", \"purple\", \"pink\", \"lime\"])\n",
    "ordered_cols = [r[0] for r in sorted([(cat, stat_tab.loc[cat, cat]) for cat in categories_to_keep],\n",
    "                                     key=lambda x: x[1], reverse=True)]\n",
    "cat_color = dict(zip(ordered_cols, [i[0] for i in enumerate(ordered_cols)]))\n",
    "\n",
    "\n",
    "for cat in ordered_cols:\n",
    "    row = stat_tab.loc[cat, :].sort_values(ascending=False)\n",
    "    idxs = row.index\n",
    "    vals = row.values\n",
    "    for i, tup in enumerate(zip(idxs, vals)):\n",
    "        plt.bar(x=cat, height=tup[1], bottom=sum(vals[:i]), label=tup[0], color=c_map[cat_color.get(tup[0])])\n",
    "        if not i:\n",
    "            plt.text(s=str(tup[1]), x=tup[0], y=tup[1]/2, rotation=90, fontsize=20, ha=\"center\", va=\"center\")\n",
    "\n",
    "\n",
    "plt.legend(stat_tab.loc[ordered_cols[0], :].sort_values(ascending=False).index, loc=1)\n",
    "plt.hlines(y=50, xmin=-0.5, xmax=len(ordered_cols)-0.5, colors=[0.15, 0.2, 0], linestyle=\"dashed\")\n",
    "plt.text(s=\"50%\", x=-0.7, y =50, ha=\"center\", va=\"center\", fontsize=14)\n",
    "plt.title(\"Average Distribution Between Categories of Top 10 Closest Titles for Every Title in a Category Group\", fontdict={\"size\":20})\n",
    "plt.xlabel(\"Categories\", fontdict={\"size\":18})\n",
    "plt.ylabel(\"Average Distribution, %\", fontdict={\"size\":18})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c11c46",
   "metadata": {},
   "source": [
    "##### It can be seen that titles from 'sportas' category should be the easiest to distinguish from the others - more than 3/4 of all titles from this category had a title from the same category very similar to itself.\n",
    "##### 'verslas' category has the second highest score here even though it is noticeably mixed up with 'eismas', 'mokslas-it-it', 'sveikata'  and 'nuomones' categories. The reason for it may be the fact that this category has a huge number of titles in the dataset - around 25 %, so it was less difficult for titles to find a similar one from the same category.\n",
    "##### 'muzika' category is mixed up with 'kultura' the most and the later tend to be similar with 'nuomones' category.\n",
    "##### 'eismas' is mixed up with 'kriminalai' - it may be due to the fact that incidents often involve traffic.\n",
    "##### Titles from 'sveikata' category find similarity with titles from 'mokslas-ir-it' the most.\n",
    "##### The chart suggests that the hardest task will be to distinguish titles from 'nuomones' category because it mixes up with other categories the most. This may be the truth because titles from this category can be on many topics and the reason for them to be classified as 'nuomones' is that it represents someone's opinion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ccc117",
   "metadata": {},
   "source": [
    "# 3. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc94347d",
   "metadata": {},
   "source": [
    "### Finding useful features for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f61af37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a559ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from imblearn.over_sampling import RandomOverSampler\n",
    "except:\n",
    "    from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a8d322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, X_title_col, X_num_cols, target_col, use_oversampler):\n",
    "    \"\"\"Split data into train and test datasets\"\"\"\n",
    "    if not X_num_cols:  # Only 'title' feature should be in the final X datasets\n",
    "        # Splitting data into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df[X_title_col], df[target_col], test_size=0.3, random_state=420)\n",
    "    \n",
    "    else:  # Numerical features should be included in the final X datasets\n",
    "        # Splitting data into train and test sets\n",
    "        X_cols = X_num_cols.copy()\n",
    "        X_cols.append(X_title_col)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df[X_cols], df[target_col], test_size=0.3, random_state=420)\n",
    "    \n",
    "    # Checking if oversampling should be used\n",
    "    if use_oversampler == \"RandOv\":\n",
    "        ovs = RandomOverSampler(random_state=420)\n",
    "        X_train, y_train = ovs.fit_resample(X_train, y_train)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ca468d",
   "metadata": {},
   "source": [
    "##### Splitting data into training and testing feature sets and their target labels, in order for it to be in a suitable format for the model and to have 'unseen' data to test the model with.\n",
    "##### Oversampling increases the amount of total titles in the dataset for smaller categories so that the share for each of them would be equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7732aac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_titles(X_train, X_test, X_title_col, X_num_cols):\n",
    "    \"\"\"Convert titles to vectors\"\"\"\n",
    "    vectorizer = CountVectorizer()\n",
    "    \n",
    "    if not X_num_cols:  # X datasets contain only 'title' feature\n",
    "        X_train_vect = vectorizer.fit_transform(X_train.values)\n",
    "        X_test_vect = vectorizer.transform(X_test.values)\n",
    "    \n",
    "    else:  # X datasets contain more than one feature\n",
    "        X_train_vect = vectorizer.fit_transform(X_train[X_title_col].values)\n",
    "        X_test_vect = vectorizer.transform(X_test[X_title_col].values)\n",
    "    \n",
    "    return X_train_vect, X_test_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df804be6",
   "metadata": {},
   "source": [
    "##### Processing titles from text to numeric data - vectors, so it could be used in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56794ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(X_train, X_test):\n",
    "    \"\"\"Scale numerical features\"\"\"\n",
    "    sc = StandardScaler()\n",
    "    \n",
    "    X_train_scaled = sc.fit_transform(X_train)\n",
    "    X_test_scaled = sc.transform(X_test)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55b997a",
   "metadata": {},
   "source": [
    "##### Scaling numeric features helps the model to better fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4e2963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, X_title_col, X_scale_cols, X_non_scale_cols, target_col, use_oversampler):\n",
    "    \"\"\"Preparing data for model\"\"\"\n",
    "    # Checking if there are more features in X datasets excluding 'title'\n",
    "    X_num_cols = X_scale_cols.copy()\n",
    "    X_num_cols += X_non_scale_cols\n",
    "    \n",
    "    # Splitting data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = split_data(df, X_title_col, X_num_cols, target_col, use_oversampler)\n",
    "    \n",
    "    # Vectorizing titles\n",
    "    X_train_vect, X_test_vect = vectorize_titles(X_train, X_test, X_title_col, X_num_cols)\n",
    "    \n",
    "    if X_scale_cols:  # Scalable features should be included in the final X datasets\n",
    "        # Scaling numerical features\n",
    "        X_train_scaled, X_test_scaled = scale_features(X_train[X_scale_cols], X_test[X_scale_cols])\n",
    "        \n",
    "        # Combining vectorized titles and scaled features\n",
    "        X_train_final = scipy.sparse.hstack([X_train_vect, X_train_scaled])\n",
    "        X_test_final = scipy.sparse.hstack([X_test_vect, X_test_scaled])\n",
    "        \n",
    "    else:  # No scalable features the X datasets\n",
    "        X_train_final, X_test_final = X_train_vect, X_test_vect\n",
    "    \n",
    "    if X_non_scale_cols:  # Additional numerical features should be included in the final X datasets\n",
    "        X_train_final = scipy.sparse.hstack([X_train_final, X_train[X_non_scale_cols]])\n",
    "        X_test_final = scipy.sparse.hstack([X_test_final, X_test[X_non_scale_cols]])\n",
    "    \n",
    "    # Converting target labels from strings to numbers\n",
    "    cat_to_label = dict(zip(categories_to_keep, [i[0] for i in enumerate(categories_to_keep)]))\n",
    "    y_train = np.array(y_train.map(cat_to_label).values)\n",
    "    y_test = np.array(y_test.map(cat_to_label).values)\n",
    "    \n",
    "    return X_train_final, X_test_final, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7553155a",
   "metadata": {},
   "source": [
    "##### Using previous 3 functions to convert the data into suitable format for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec36ef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_and_stats(df, X_title_col=\"title\", X_scale_cols: list = [], X_non_scale_cols: list = [], target_col=\"category\",\n",
    "                   use_oversampler: [\"None\", \"RandOv\"] = \"None\"):\n",
    "    \"\"\"Train model and get results\"\"\"\n",
    "    # Getting data\n",
    "    X_train, X_test, y_train, y_test = prepare_data(df, X_title_col, X_scale_cols, X_non_scale_cols, target_col, use_oversampler)\n",
    "    \n",
    "    # Creating and training the model\n",
    "    lr = LogisticRegression(multi_class=\"ovr\", random_state=420, max_iter=500)\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    # Getting predictions and calculating model performance results\n",
    "    y_pred = lr.predict(X_test)\n",
    "    train_acc = lr.score(X_train, y_train)\n",
    "    test_acc = accuracy_score(y_test, y_pred)\n",
    "    test_f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    \n",
    "    print(f\"Model's accuracy on training data: {train_acc:.5f}\")\n",
    "    print(f\"Model's accuracy on test data: {test_acc:.5f}\")\n",
    "    print(f\"Model's f1_score: {test_f1:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff978fe",
   "metadata": {},
   "source": [
    "##### Getting data, creating and training the model, calculating results. These functions were created to help compare the performance of  models trained with different data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6959ec88",
   "metadata": {},
   "source": [
    "#### Now for better understanding the steps of training the benchmark model will be explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3264627d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everytime data will be split into 70% training and 30% testing datasets.\n",
    "# The same (random_state) will be used for reproducibility.\n",
    "X_train, X_test, y_train, y_test = train_test_split(pur_df[\"title\"], pur_df[\"category\"], test_size=0.3,\n",
    "                                                    random_state=420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d06d23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.size, y_train.size, X_test.size, y_test.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d2b8df",
   "metadata": {},
   "source": [
    "##### Train set has 69649 titles and test has 29850 titles from every category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bbfd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10% of titles ditribution between categories in the train dataset\n",
    "y_train.value_counts()/7  # dividing by 7 because train set is 7 parts of the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22d33a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10% of titles ditribution between categories in the test dataset\n",
    "y_test.value_counts()/3  # dividing by 3 because test set is 3 parts of the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1c0556",
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_train.value_counts()/7) / (y_test.value_counts()/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa93d396",
   "metadata": {},
   "source": [
    "##### Both datasets have very similar distribution of titles between categories - scores are near 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd39b456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dictionary will be used to encode categories\n",
    "cat_to_label = dict(zip(categories_to_keep, [i[0] for i in enumerate(categories_to_keep)]))\n",
    "cat_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0839e610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categories\n",
    "y_train = np.array(y_train.map(cat_to_label).values)\n",
    "y_test = np.array(y_test.map(cat_to_label).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c33edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f6923f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating count vectorizer and converting titles in the train dataset to vectors\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X_train_vect = vectorizer.fit_transform(X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b45b6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d4efa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb767306",
   "metadata": {},
   "source": [
    "##### The title column was converted to 80012 columns for each set of characters, for example '000' or 'zyniai', that was found in titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494970bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting titles in the test dataset to vectors\n",
    "X_test_vect = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cbf78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee99be18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model - multiclass logistic regression\n",
    "# (random_state) will be used for reproducibility and (max_iter) is increased, in order for the model to have enough iterations\n",
    "# to fit the data\n",
    "lr = LogisticRegression(multi_class=\"ovr\", random_state=420, max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f8da68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training the model with train dataset\n",
    "lr.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d311e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the model to predict the categories for titles in the test dataset\n",
    "y_pred = lr.predict(X_test_vect)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db28f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53d3d1a",
   "metadata": {},
   "source": [
    "##### It is visible that first 3 and last 3 titles were categorized correctly but scoring metrics should be used to get the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc1ee1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the accuracy score that model reaches then predicting categories of titles from train dataset\n",
    "lr.score(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfdaac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the accuracy score that model reaches then predicting categories of titles from test dataset\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2527aec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the f1 score that model reaches then predicting categories of titles from test dataset\n",
    "f1_score(y_test, y_pred, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86cd2c1",
   "metadata": {},
   "source": [
    "##### Benchmark model has 0.87052 accuracy and 0.87011 f1 score - the higher the better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db333a93",
   "metadata": {},
   "source": [
    "##### Using the functions defined earlier to get the performance results of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fee0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark model\n",
    "model_and_stats(pur_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca089408",
   "metadata": {},
   "source": [
    "##### It can be seen that results are the same - functions work! Now models will be trained with different features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000cea0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Adding top 10 titles distribution between categories, using RandomOverSampler\n",
    "model_and_stats(pur_df, X_scale_cols=categories_to_keep, use_oversampler=\"RandOv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff56914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding title length and word count, using RandomOverSampler\n",
    "model_and_stats(pur_df, X_scale_cols=[\"title_length\", \"word_count\"], use_oversampler=\"RandOv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83938989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding top 10 titles distribution between categories, title length and word count, using RandomOverSampler\n",
    "model_and_stats(pur_df, X_scale_cols=list(pur_df.columns[2:]), use_oversampler=\"RandOv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4840c128",
   "metadata": {},
   "source": [
    "##### The best results are reached when using features title, title length, word count and random over sampler:\n",
    "- 0.87300 accuracy score\n",
    "- 0.87344 f1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a518cea3",
   "metadata": {},
   "source": [
    "### Pipeline and GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309a6bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data using only the best features\n",
    "X_train, X_test, y_train, y_test = split_data(pur_df, \"title\", [\"title_length\", \"word_count\"], \"category\", \"RandOv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997fd93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_title_column(X):\n",
    "    \"\"\"Returns column 'title'\"\"\"\n",
    "    return X[\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337aae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_numeric_columns(X):\n",
    "    \"\"\"Returns columns 'title_length' and 'word_count'\"\"\"\n",
    "    return X[[\"title_length\", \"word_count\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46c9b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two functions above will be used in the pipeline to be able to transform text and numerical data differently but they need\n",
    "# to have fit and fit_transform methods. Function transformer change them for this purpose.\n",
    "get_text_data = FunctionTransformer(return_title_column, validate=False)\n",
    "get_numeric_data = FunctionTransformer(return_numeric_columns, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e166d5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using feature union to be able to transform text and numerical data differently and then combine them together in the pipeline\n",
    "process_and_join_features = FeatureUnion(transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('scaler', StandardScaler())  # Scaling numerical data ('title_length', 'word_count') with standard scaler\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    (\"selector\", get_text_data),\n",
    "                    (\"vectorizer\", CountVectorizer())  # Converting text data ('title') to vectors\n",
    "                ]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1577db9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining all steps - from data transformation to model creation - in one object: pipeline\n",
    "pipe = Pipeline([\n",
    "        ('union', process_and_join_features),\n",
    "        ('lr', LogisticRegression(multi_class=\"ovr\", random_state=420, max_iter=500))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b58c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameters that GridSerchCV should try out and find the best ones for the model\n",
    "params = {\n",
    "    \"union__text_features__vectorizer__ngram_range\": [(1, 1), (1, 2), (1, 3), (2, 3)],\n",
    "    \"union__text_features__vectorizer__max_df\": [0.3, 0.1, 0.01, 0.005],\n",
    "    \"lr__penalty\": [\"l2\", \"none\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb993918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating GridSearchCV object, using 5-fold cross-validation and accuracy as a score metric\n",
    "gs = GridSearchCV(estimator=pipe, param_grid=params, scoring=\"accuracy\", cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729a3184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training GridSeachCV object\n",
    "# !TAKES A FEW HOURS! Set 'proceed_gs = True' if you want to calculate the results from the start.\n",
    "proceed_gs = False\n",
    "if proceed_gs:\n",
    "    gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcf7811",
   "metadata": {},
   "outputs": [],
   "source": [
    "if proceed_gs:\n",
    "    gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ee9113",
   "metadata": {},
   "outputs": [],
   "source": [
    "if proceed_gs:\n",
    "    gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31971068",
   "metadata": {},
   "source": [
    "##### Best results are achieved by using:\n",
    "- CountVectorizer:\n",
    "    - ngram_range = (1, 2)\n",
    "    - max_df = 0.3\n",
    "- LogisticRegression:\n",
    "    - penalty = 'l2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e011e88",
   "metadata": {},
   "source": [
    "### Creating and training a model with the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ffae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_and_join_features = FeatureUnion(transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('scaler', StandardScaler())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    (\"selector\", get_text_data),\n",
    "                    (\"vectorizer\", CountVectorizer(ngram_range=(1, 2), max_df=0.3))  # Setting ngram_range=(1, 2) and max_df=0.3\n",
    "                ]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfaaf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "        ('union', process_and_join_features),\n",
    "        ('lr', LogisticRegression(multi_class=\"ovr\", random_state=420, max_iter=500)) # penalty='l2' is default, no need to specify\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8754a62d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training the model\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5781b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting categories for titles in the test dataset\n",
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5406f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb7fe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da8e28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, y_pred, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292dc4b5",
   "metadata": {},
   "source": [
    "##### Comparing final and benchmark models\n",
    "- 87.481 % vs. 87.052 %: accuracy score increased by 0.429 %\n",
    "- 87.487 % vs. 87.011 %: f1 score increased by 0.476 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c23d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving final model locally\n",
    "with open(\"../FlaskApp/model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(pipe, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6adbe77",
   "metadata": {},
   "source": [
    "## Final Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22464fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating how many titles were asigned to different categories\n",
    "# Getting all titles from categories in (categories_to_keep) list\n",
    "t = df_cat[df_cat[\"category\"].isin(categories_to_keep)].copy()\n",
    "\n",
    "\n",
    "# Finding combinations of categories from titles that were calssified in multiple categories\n",
    "t_c_d = [\"+\".join(sorted(list(v))) for v in t[t.duplicated(\"title\", keep=False)]\\\n",
    "         .groupby(\"title\")[\"category\"].unique().values if len(v) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e7739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the frequencies of multi-categories combinations\n",
    "Counter(t_c_d), print(len(t_c_d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc8eecc",
   "metadata": {},
   "source": [
    "##### 3911 titles were asigned to multiple categories, most frequently:\n",
    "- 'mokslas-ir-it' and 'verslas'\n",
    "- 'eismas' and 'verslas'\n",
    "- 'kultura' and 'muzika'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea81a907",
   "metadata": {},
   "source": [
    "##### 3911 out of 99499 or almost 4 % of titles in the final datset were previously classified in multiple categories. This shows that the task to assign a title to only one category isn't that easy even for the authors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
